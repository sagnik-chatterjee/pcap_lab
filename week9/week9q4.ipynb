{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week9q4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGa5v9rQWyYd",
        "outputId": "2a82159c-2d39-404d-a658-a0f63ea023b9"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-n3hd2ur9\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-n3hd2ur9\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=40acb5fcf40f96722ee19cb9c8dbdcb52330d76eb01d6e4e22e50854e5382eb4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pwcrkgon/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9cKEHadW0qk",
        "outputId": "c346b23d-10e8-4ca4-e8cc-08e41228ef1b"
      },
      "source": [
        "%%cu\n",
        "#include<stdio.h>\n",
        "#include<stdlib.h>\n",
        "#define Mask_Width 5\n",
        " \n",
        "__global__ void Convolution_global(int *src, int *res, int *d_mask, int src_length){\n",
        "    //taking the threadid\n",
        "    int id =  blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(id < src_length){\n",
        "        //declaring the start point\n",
        "        int start = id - (Mask_Width / 2);\n",
        "              int pval = 0;\n",
        "    \n",
        "       //Looping throught the array and multiplying with the mask array\n",
        "        for(int i = 0; i < Mask_Width; i++){\n",
        "            if((start + i) >= 0 && (start + i) < src_length){\n",
        "               // printf(\"elements being multiplied are: src = %d mask = %d\\n\", src[start + i], d_mask[i]);\n",
        "                pval += (src[start + i] * d_mask[i]);\n",
        "               // printf(\"pval = %d\\n\", pval);\n",
        "            }\n",
        "        }\n",
        " \n",
        "        //storing the answer in the resultant array\n",
        "        res[id] = pval;        \n",
        "      }\n",
        "}\n",
        " \n",
        "int main(){\n",
        "    //Initializing the input array and the mask array\n",
        "    int n = 8;\n",
        "    int input [] = {8, 9, 3, 4, 5, 6, 11, 67};\n",
        "    int mask[] = {7, 8, 9, 10, 11};\n",
        "    int size_input = sizeof(int) * n;\n",
        "    int size_mask = sizeof(int) * Mask_Width;\n",
        "    int h_output[n];\n",
        " \n",
        "    //Allocating space in the device\n",
        "    int *d_input, *d_output, *d_mask_s;\n",
        "    cudaMalloc((void **)&d_input, size_input);\n",
        "    cudaMalloc((void **)&d_output, size_input);\n",
        "    cudaMalloc((void **)&d_mask_s, size_mask);\n",
        " \n",
        "    //Copying to the device memory\n",
        "    cudaMemcpy(d_input, input, size_input, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_mask_s, mask, size_mask, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //Creating event to calculate the time elapsed\n",
        "    float et;\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start); cudaEventCreate(&stop);\n",
        " \n",
        "    //Calling the kernel along with time calculation\n",
        "    int threads = 4;\n",
        "    int blocks = (threads + n - 1) / threads;\n",
        "    cudaEventRecord(start);\n",
        "    Convolution_global<<<blocks, threads>>>(d_input, d_output, d_mask_s, n);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaDeviceSynchronize();\n",
        "    //Calculating the elapsed time of first kernel\n",
        "    cudaEventElapsedTime(&et, start, stop);\n",
        "    printf(\"\\nThe time taken by global memory kernel to execute is: %f milliseconds\\n\", et);\n",
        " \n",
        "    //Copying the shared memory result to host\n",
        "    cudaMemcpy(h_output, d_output, size_input, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    //printing the result\n",
        "    printf(\"\\nPrinting the input array:\\n\");\n",
        "    for(int i = 0; i < n; i++){\n",
        "        printf(\"%d\\t\", input[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    printf(\"\\nPrinting the mask array:\\n\");\n",
        "    for(int i = 0; i < Mask_Width; i++){\n",
        "        printf(\"%d\\t\", mask[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    printf(\"\\nPrinting the resultant array:\\n\");\n",
        "    for(int i = 0; i < n; i++){\n",
        "        printf(\"%d\\t\", h_output[i]);\n",
        "    }\n",
        " \n",
        "    //Freeing the cuda resources\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_mask_s);\n",
        " \n",
        "}\n",
        " \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The time taken by global memory kernel to execute is: 0.018752 milliseconds\n",
            "\n",
            "Printing the input array:\n",
            "8\t9\t3\t4\t5\t6\t11\t67\t\n",
            "\n",
            "Printing the mask array:\n",
            "7\t8\t9\t10\t11\t\n",
            "\n",
            "Printing the resultant array:\n",
            "195\t219\t250\t239\t279\t969\t852\t733\t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week8_q1_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMKL6lHj_nxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a60317-8402-4cb6-ba4e-765e6656b397"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-6aj9mn20\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-6aj9mn20\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.7/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=254bf9f2d0cf771a4c1a03fab12fd3c0056678ceec0875f5960c42c0340b45ef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wpmmevku/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtUkZ8G_AbWY",
        "outputId": "781b3729-9814-4f1f-b66b-13a5fc6ac4fb"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLwb1dvyAefa",
        "outputId": "0eac125c-fd2f-4786-b1f9-e57f671b6ba3"
      },
      "source": [
        "%%cu \n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "//have to take this in row major format\n",
        "\n",
        "\n",
        "#define N 2\n",
        "\n",
        "void generateRandomArray(int* arrayA,int *arrayB) {\n",
        "\tsrand((unsigned) time(NULL));\n",
        "\tfor(int i = 0; i<N*N; ++i){\n",
        "\t\tarrayA[i] = ((int)rand()/(int)(RAND_MAX)) * 100;\n",
        "\t\tarrayB[i] = ((int)rand()/(int)(RAND_MAX)) * 100;\n",
        "\t\t\n",
        "\t}\n",
        "}\n",
        "\n",
        "__global__ void matrixAddColOnly(int *A,int *B,int *C){\n",
        "    int colId = threadIdx.x+blockIdx.x*blockDim.x;\n",
        "\n",
        "    if(colId <2){\n",
        "        for(int i=0;i<2;i++){\n",
        "            C[colId+i*2] = A[colId+i*2]+B[colId+i*2];\n",
        "        }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    //in actuality a 2*2 matrix\n",
        "\n",
        "    const size_t d_size = sizeof(int) * size_t(N*N);\n",
        "\n",
        "    int *A = (int*) malloc(N*N * sizeof(int));\n",
        "\t  int *B = (int*) malloc(N*N * sizeof(int));\n",
        "\t  int *C = (int*) malloc(N*N * sizeof(int));\n",
        "    //generateRandomArray(A,B);\n",
        "    for(int i=0;i<N*N;i++){\n",
        "        A[i]=4*i+1;\n",
        "    }\n",
        "    for(int i=0;i<N*N;i++){\n",
        "        B[i]=5*i+2;\n",
        "    }\n",
        "    for(int i=0;i<N*N;i++){\n",
        "        C[i]=0;\n",
        "    }\n",
        "\n",
        "    int *pA , *pB,*pC;\n",
        "    cudaMalloc((void**)&pA,d_size);\n",
        "    cudaMalloc((void**)&pB,d_size);\n",
        "    cudaMalloc((void**)&pC,d_size);\n",
        "\n",
        "    cudaMemcpy(pA,A,d_size,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(pB,B,d_size,cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(pC,C,d_size,cudaMemcpyHostToDevice);\n",
        "    int numBlocks=1; //cause using single block\n",
        "    dim3 threadsPerBlock(N,N);\n",
        "    dim3 blocksPerGrid(1,1);\n",
        "    matrixAddColOnly<<<blocksPerGrid,threadsPerBlock>>>(pA,pB,pC);\n",
        "    cudaMemcpy(C,pC,d_size,cudaMemcpyDeviceToHost);\n",
        "    for(int i=0;i<N*N;i++){\n",
        "        printf(\"A: =%d, \",A[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    for(int i=0;i<N*N;i++){\n",
        "        printf(\"B: =%d, \",B[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "    for(int i=0;i<N*N;i++){\n",
        "        printf(\"C: =%d, \",C[i]);\n",
        "    }\n",
        "   \n",
        "\n",
        "    cudaFree(pA);\n",
        "    cudaFree(pB);\n",
        "    cudaFree(pC);\n",
        "    free(A);\n",
        "    free(B);\n",
        "    free(C);\n",
        "    return 0;\n",
        "\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A: =1, A: =5, A: =9, A: =13, \n",
            "B: =2, B: =7, B: =12, B: =17, \n",
            "C: =3, C: =12, C: =21, C: =30, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSWX7ENgA_P2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
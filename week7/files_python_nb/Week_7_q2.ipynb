{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week_7_q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRShVEJBD8yF"
      },
      "source": [
        "# parallel selection sort\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8r_9vIUEDs1",
        "outputId": "3125db58-f86e-474f-cb6e-6f2e2e4c73ad"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-x7ef0edc\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-x7ef0edc\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.7/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp37-none-any.whl size=4307 sha256=791de4c2ce6defedab9f68b15b131b62e759b5f105b521b073d80f40ecffdb87\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qwidqhe1/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfBLiL7bEEJ3",
        "outputId": "22c81e01-4e4b-421c-80db-6e7564a135de"
      },
      "source": [
        "%load_ext nvcc_plugin "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-IvCAynEMCN",
        "outputId": "f8a24a77-797f-4a6e-cdec-bfffb92d395b"
      },
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <math.h>\n",
        "__global__ void parallel_kernel_pos(int *a, int n)\n",
        "{\n",
        " int i = threadIdx.x;\n",
        " int data = a[i];\n",
        " int pos = 0;\n",
        " for (int j = 0; j < n; j++)\n",
        " {\n",
        " if (a[j] < data || (a[j] == data && j < i))\n",
        " pos++;\n",
        " }\n",
        " a[pos] = data;\n",
        "}\n",
        "void sortArr(int* h_arr, int n){\n",
        " int* d_arr = NULL;\n",
        " int size = n*sizeof(int);\n",
        " cudaError_t err = cudaSuccess;\n",
        " err = cudaMalloc((void **)&d_arr,size);\n",
        " if(err != cudaSuccess){\n",
        " printf(\"%s\\n\",cudaGetErrorString(err));\n",
        " exit(EXIT_FAILURE);\n",
        " }\n",
        " err = cudaMemcpy(d_arr,h_arr,size,cudaMemcpyHostToDevice);\n",
        " if(err != cudaSuccess){\n",
        " printf(\"%s\\n\",cudaGetErrorString(err));\n",
        " exit(EXIT_FAILURE);\n",
        " }\n",
        " parallel_kernel_pos<<<1,n>>>(d_arr,n);\n",
        " cudaMemcpy(h_arr,d_arr,size,cudaMemcpyDeviceToHost);\n",
        " cudaFree(d_arr);\n",
        "}\n",
        "int main(){\n",
        " int n = 10;\n",
        " int* arr = (int*)malloc(n*sizeof(int));\n",
        " for(int i=0;i<n;i++){\n",
        " arr[i] = rand()%50;\n",
        " }\n",
        " for(int i=0;i<10;i++){\n",
        " printf(\"%d \",arr[i]);\n",
        " }\n",
        " //after sorting \n",
        " sortArr(arr,n);\n",
        " printf(\"\\n\");\n",
        " for(int i=0;i<10;i++){\n",
        " printf(\"%d \",arr[i] );\n",
        " }\n",
        " return 0;\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33 36 27 15 43 35 36 42 49 21 \n",
            "33 36 27 15 43 35 36 42 49 21 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqZemBqxEXc7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}